/*----------------------------------------------------
Copyright 2017 Xilinx, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
----------------------------------------------------*/

#ifndef __XCHANGE_STRUCTS_HPP__
#define __XCHANGE_STRUCTS_HPP__

#include "hw_settings.h"

//# Index Pair for input and output dependencies
struct _indexpair
{
	short seqidx;
	short pos;
};
typedef struct _indexpair layerID;

//# Index Pair for input and output dependencies
struct _qformat
{
	int ip_bw;
	int ip_fbits;
	int op_bw;
	int op_fbits;
	int wt_bw;
	int wt_fbits;
	int bs_bw;
	int bs_fbits;
};
typedef struct _qformat qformat;

//# Layers supported
enum _kernel_type{
	CONV,
	POOL,
	FC_LAYER,
	SOFTMAX,
	DECONV,
	NORM,
	PERMUTE,
	NMS,
	CROP,
	ELTWISEADD,
	XCUSTOM,
	XPACK,
	XUNPACK
};
typedef _kernel_type kernel_type_e;

//# Class to hold data required to schedule kernels
//# This will be filled by XChange Block from the data available in xLayer &
//# offsets generated by Buffer Management Block.
class xChangeLayer
{
public:
	kernel_type_e kernType;
	kernel_type_e prev_kernType;
	int kernMode;
	int prev_kernMode;
	std::string kernexecType;
	int input_sizebytes;
	int output_sizebytes;
	int output_size;
	void * in_ptrs[INPUT_PORTS];
	void * out_ptrs[OUTPUT_PORTS];
	void * wts_ptrs[WEIGHT_PORTS];
	void * bias_ptr;
	void * params; 					// Total : MAX_PARAM_SIZE
	void * mean;
	
	std::vector<void *> xtra_ptrs;
	
	std::vector<layerID> previous;
	std::vector<layerID> next;
	qformat qf_format;
	
	int resize_h;
	int resize_w;
	
	std::vector<float> float_params;  //added for NMS
	std::vector<bool> layer_done;
	
	char *ref_path;
	char *out_path;
	char *base_path;
	char *wgt_path;
	char *bias_path;

	int en_batch_size_one;

	//Custom Layer suppport arguments
	std::vector<std::vector<int> > input_dims;// Dimesions of input blobs
	std::vector<std::vector<int> > output_dims;// Dimesions of input blobs
	std::vector<int> output_dim;         // Output dimension should come from the user
	std::vector<float> float_args;       // All float, int and boolean args from prototxt will be here
	std::vector<std::string> string_args;     // All string args from prototxt will be here.
	std::vector<std::vector<float> > custom_float_params;  // Trained parameters of the layer
	std::vector<std::vector<int> > params_dims;// dimensions of parameters
	std::string custom_layer_type;
	bool custom_reluflag;
	
	//layer-wise latency breakup params
	long long startclk;
	long long endclk;
	std::string layername;

	//# Constructor
	xChangeLayer() {}
	xChangeLayer(kernel_type_e Type) 
	{
		kernType = Type;
	}

    //# Destructor
    ~xChangeLayer()
	{}

	//# Utils
	void DisplayParams(void);
	void DisplayParams(int);
};

struct _bufPtrs
{
	std::vector<void*> hwBufs;
	std::vector<void*> swBufs;
	int size;
};
typedef _bufPtrs bufPtrs;

struct chaihandle
{
	std::vector<xChangeLayer> JobQueue[NUM_IMG];
	bufPtrs ptrsList;
};
typedef chaihandle chaihandle_t;


#endif // __XCHANGE_STRUCTS_HPP__
